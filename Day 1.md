## Day 1 â€“ Platform Setup & First Steps  
ðŸ“… Date: 09/01/2026

### ðŸ“Œ Objective
Understand Databricks fundamentals and complete the initial platform setup.

---

### ðŸ“˜ What I Learned
- Why **Databricks** is preferred over traditional **Pandas** and **Hadoop**
- High-level overview of **Lakehouse Architecture**
- Databricks workspace components:
  - Notebooks
  - Compute (Clusters)
  - Data Explorer
- Real-world adoption of Databricks in companies like Netflix and Shell

---

### ðŸ› ï¸ Hands-on Tasks Completed
- Created **Databricks Community Edition** account
- Explored Workspace, Compute, and Data tabs
- Generated **Kaggle API credentials**
- Connected Kaggle with Databricks
- Downloaded and loaded an e-commerce dataset
- Executed first **PySpark DataFrame operations**

---

### ðŸ§ª Practice Code
```python
# Create a simple DataFrame
data = [("iPhone", 999), ("Samsung", 799), ("MacBook", 1299)]
df = spark.createDataFrame(data, ["product", "price"])
df.show()

# Filter expensive products
df.filter(df.price > 1000).show()
